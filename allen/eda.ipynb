{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "torch.cuda.is_available()\n",
    "torch.cuda.device_count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tempfile\n",
    "import json\n",
    "import re\n",
    "from typing import Dict, Iterable, List\n",
    "\n",
    "import torch\n",
    "from torch import optim\n",
    "from allennlp.data.dataset_readers.dataset_reader import AllennlpDataset\n",
    "from allennlp.data import DatasetReader, Instance, Vocabulary, Token, DataLoader\n",
    "from allennlp.data.fields import LabelField, TextField, SpanField\n",
    "from allennlp.data.token_indexers import (\n",
    "    TokenIndexer,\n",
    "    SingleIdTokenIndexer,\n",
    "    TokenCharactersIndexer,\n",
    "    ELMoTokenCharactersIndexer,\n",
    "    PretrainedTransformerIndexer,\n",
    "    PretrainedTransformerMismatchedIndexer,\n",
    ")\n",
    "from allennlp.data.tokenizers import (\n",
    "    Tokenizer,\n",
    "    CharacterTokenizer,\n",
    "    PretrainedTransformerTokenizer,\n",
    "    SpacyTokenizer,\n",
    "    WhitespaceTokenizer,\n",
    ")\n",
    "from allennlp.modules.token_embedders import (\n",
    "    Embedding,\n",
    "    TokenCharactersEncoder,\n",
    "    ElmoTokenEmbedder,\n",
    "    PretrainedTransformerEmbedder,\n",
    "    PretrainedTransformerMismatchedEmbedder,\n",
    ")\n",
    "from allennlp.training.trainer import GradientDescentTrainer, Trainer\n",
    "from allennlp.training.optimizers import AdamOptimizer\n",
    "from allennlp.models import Model\n",
    "from allennlp.modules import TextFieldEmbedder, Seq2VecEncoder, Seq2SeqEncoder\n",
    "from allennlp.modules.text_field_embedders import BasicTextFieldEmbedder\n",
    "from allennlp.modules.seq2seq_encoders import PassThroughEncoder\n",
    "from allennlp.data.samplers import BasicBatchSampler, BucketBatchSampler, SequentialSampler\n",
    "from allennlp.nn import util\n",
    "from allennlp.training.metrics import CategoricalAccuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = './data/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>textID</th>\n",
       "      <th>text</th>\n",
       "      <th>selected_text</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>cb774db0d1</td>\n",
       "      <td>I`d have responded, if I were going</td>\n",
       "      <td>I`d have responded, if I were going</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>549e992a42</td>\n",
       "      <td>Sooo SAD I will miss you here in San Diego!!!</td>\n",
       "      <td>Sooo SAD</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>088c60f138</td>\n",
       "      <td>my boss is bullying me...</td>\n",
       "      <td>bullying me</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9642c003ef</td>\n",
       "      <td>what interview! leave me alone</td>\n",
       "      <td>leave me alone</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>358bd9e861</td>\n",
       "      <td>Sons of ****, why couldn`t they put them on t...</td>\n",
       "      <td>Sons of ****,</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       textID                                               text  \\\n",
       "0  cb774db0d1                I`d have responded, if I were going   \n",
       "1  549e992a42      Sooo SAD I will miss you here in San Diego!!!   \n",
       "2  088c60f138                          my boss is bullying me...   \n",
       "3  9642c003ef                     what interview! leave me alone   \n",
       "4  358bd9e861   Sons of ****, why couldn`t they put them on t...   \n",
       "\n",
       "                         selected_text sentiment  \n",
       "0  I`d have responded, if I were going   neutral  \n",
       "1                             Sooo SAD  negative  \n",
       "2                          bullying me  negative  \n",
       "3                       leave me alone  negative  \n",
       "4                        Sons of ****,  negative  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df = pd.read_csv(os.path.join(data_dir, 'train.csv'))\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 27481 entries, 0 to 27480\n",
      "Data columns (total 4 columns):\n",
      " #   Column         Non-Null Count  Dtype \n",
      "---  ------         --------------  ----- \n",
      " 0   textID         27481 non-null  object\n",
      " 1   text           27480 non-null  object\n",
      " 2   selected_text  27480 non-null  object\n",
      " 3   sentiment      27481 non-null  object\n",
      "dtypes: object(4)\n",
      "memory usage: 858.9+ KB\n"
     ]
    }
   ],
   "source": [
    "train_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.selected_text[0] in train_df.text[0] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 27480 entries, 0 to 27480\n",
      "Data columns (total 4 columns):\n",
      " #   Column         Non-Null Count  Dtype \n",
      "---  ------         --------------  ----- \n",
      " 0   textID         27480 non-null  object\n",
      " 1   text           27480 non-null  object\n",
      " 2   selected_text  27480 non-null  object\n",
      " 3   sentiment      27480 non-null  object\n",
      "dtypes: object(4)\n",
      "memory usage: 1.0+ MB\n"
     ]
    }
   ],
   "source": [
    "train_df.dropna(inplace=True)\n",
    "train_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(text):\n",
    "#     text = re.sub(r'\\S*@\\S*\\s?', '', text)\n",
    "    text = re.sub(r'\\s+', ' ', text)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extend(row):\n",
    "    selected_text = row.selected_text\n",
    "    text = row.text\n",
    "    assert selected_text in text, \"origin selected text not in origin text\"\n",
    "    selected_text = clean_text(selected_text.strip())\n",
    "    text = clean_text(text.strip())\n",
    "    assert selected_text in text,( \"selected text not in text\", selected_text, text, row.selected_text, row.text)\n",
    "    start = text.index(selected_text[0])\n",
    "    end = text.rindex(selected_text[-1])\n",
    "    while start > 0 and not text[start].isspace():\n",
    "        start -= 1\n",
    "    while end < len(text) and not text[end].isspace():\n",
    "        end += 1\n",
    "    selected_text = text[start: end]\n",
    "    return pd.Series(data=[text, selected_text, row.sentiment], \n",
    "                     index=['text', 'selected_text', 'sentiment'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>selected_text</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I`d have responded, if I were going</td>\n",
       "      <td>I`d have responded, if I were going</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Sooo SAD I will miss you here in San Diego!!!</td>\n",
       "      <td>Sooo SAD I will miss you here in San Diego!!!</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>my boss is bullying me...</td>\n",
       "      <td>boss is bullying me...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>what interview! leave me alone</td>\n",
       "      <td>leave me alone</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Sons of ****, why couldn`t they put them on th...</td>\n",
       "      <td>Sons of ****,</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  \\\n",
       "0                I`d have responded, if I were going   \n",
       "1      Sooo SAD I will miss you here in San Diego!!!   \n",
       "2                          my boss is bullying me...   \n",
       "3                     what interview! leave me alone   \n",
       "4  Sons of ****, why couldn`t they put them on th...   \n",
       "\n",
       "                                   selected_text sentiment  \n",
       "0            I`d have responded, if I were going   neutral  \n",
       "1  Sooo SAD I will miss you here in San Diego!!!  negative  \n",
       "2                         boss is bullying me...  negative  \n",
       "3                                 leave me alone  negative  \n",
       "4                                  Sons of ****,  negative  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cleaned_train_df = train_df.apply(extend, axis=1)\n",
    "cleaned_train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def span(row):\n",
    "    res = row.selected_text in row.text\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "is_span = cleaned_train_df.apply(span, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "is_span.all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7f1346cc8b50>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "cleaned_train_df.text.str.len().hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "141"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cleaned_train_df.text.str.len().max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "27480"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(cleaned_train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(21984, 5496)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cleaned_train_df = cleaned_train_df.sample(frac=1, random_state=2020).reset_index(drop=True)\n",
    "split_ratio = 0.2\n",
    "split_idx = int(split_ratio * len(cleaned_train_df))\n",
    "valid_df = cleaned_train_df.iloc[:split_idx]\n",
    "train_df = cleaned_train_df.iloc[split_idx:]\n",
    "len(train_df), len(valid_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>selected_text</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5496</th>\n",
       "      <td>YAHOO! volleyball, hiking, eating a fish eye, ...</td>\n",
       "      <td>YAHOO! volleyball, hiking, eating a fish eye, ...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5497</th>\n",
       "      <td>it starts @ 6. But we will be there until they...</td>\n",
       "      <td>it starts @ 6. But we will be there until they...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5498</th>\n",
       "      <td>I didn`t check Twitter till just now. Thanks e...</td>\n",
       "      <td>Twitter till just now. Thanks everyone for al...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5499</th>\n",
       "      <td>08.05.09 partying at the Pineforest http://tin...</td>\n",
       "      <td>08.05.09 partying at the Pineforest http://tin...</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5500</th>\n",
       "      <td>aaaawww would u like an alcoholic beverage of ...</td>\n",
       "      <td>aaaawww would u like an alcoholic beverage of ...</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   text  \\\n",
       "5496  YAHOO! volleyball, hiking, eating a fish eye, ...   \n",
       "5497  it starts @ 6. But we will be there until they...   \n",
       "5498  I didn`t check Twitter till just now. Thanks e...   \n",
       "5499  08.05.09 partying at the Pineforest http://tin...   \n",
       "5500  aaaawww would u like an alcoholic beverage of ...   \n",
       "\n",
       "                                          selected_text sentiment  \n",
       "5496  YAHOO! volleyball, hiking, eating a fish eye, ...  positive  \n",
       "5497  it starts @ 6. But we will be there until they...  negative  \n",
       "5498   Twitter till just now. Thanks everyone for al...  positive  \n",
       "5499  08.05.09 partying at the Pineforest http://tin...   neutral  \n",
       "5500  aaaawww would u like an alcoholic beverage of ...   neutral  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.to_csv('./data/clean_train.csv', index=False, encoding='utf8')\n",
    "valid_df.to_csv('./data/clean_valid.csv', index=False, encoding='utf8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "transformer_model = './models/bert/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = PretrainedTransformerTokenizer(transformer_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "token_indexer = PretrainedTransformerIndexer(model_name=transformer_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = train_df.text[5600]\n",
    "selected_text = train_df.selected_text[5600]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('Defeated by a Polo', 'Defeated')"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text, selected_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens = tokenizer.tokenize(text)\n",
    "selected = tokenizer.tokenize(selected_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([[CLS], defeated, by, a, polo, [SEP]], [[CLS], defeated, [SEP]])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens, selected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor(2)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens = ['I', 'shot', 'an', 'elephant', 'in', 'my', 'pajamas', '.']\n",
    "tokens = [Token(token) for token in tokens]\n",
    "token_indexers = {'tokens': SingleIdTokenIndexer()}\n",
    "text_field = TextField(tokens, token_indexers=token_indexers)\n",
    "\n",
    "spans = [(2, 3), (5, 6)]    # ('an', 'elephant') and ('my', 'pajamas)\n",
    "span_field = SpanField(2, 3, text_field)\n",
    "print(span_field.get_padding_lengths())\n",
    "span_field.as_tensor(span_field.get_padding_lengths())[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('defeated', allennlp.data.tokenizers.token.Token)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "str(selected[1]), type(tokens[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(defeated, shot, False)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "selected[1], tokens[1], selected[1] == tokens[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[CLS], positive, [SEP]]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.tokenize('positive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "@DatasetReader.register(\"sentiment-df\")\n",
    "class SentimentDfReader(DatasetReader):\n",
    "    def __init__(self,\n",
    "                 lazy: bool = False,\n",
    "                 tokenizer: Tokenizer = None,\n",
    "                 token_indexers: Dict[str, TokenIndexer] = None,\n",
    "                 max_tokens: int = None):\n",
    "        super().__init__(lazy)\n",
    "        self.tokenizer = tokenizer or PretrainedTransformerTokenizer(transformer_model)\n",
    "        self.token_indexers = token_indexers or {'bert_tokens': PretrainedTransformerIndexer(transformer_model)}\n",
    "        self.max_tokens = max_tokens\n",
    "\n",
    "    def text_to_instance(self,\n",
    "                         tokens: List[Token],\n",
    "                         label: List[Token],\n",
    "                         span: List[int] = None) -> Instance:\n",
    "        if self.max_tokens:\n",
    "            tokens = tokens[:self.max_tokens-2]\n",
    "        tokens.extend(label)\n",
    "        text_field = TextField(tokens, self.token_indexers)\n",
    "        fields = {'text': text_field}\n",
    "        if span:\n",
    "            fields['span'] = SpanField(*span, text_field)\n",
    "        return Instance(fields)\n",
    "\n",
    "    def _read(self, file_path: str) -> Iterable[Instance]:\n",
    "        df = pd.read_csv(file_path)\n",
    "        for _, row in df.iterrows():\n",
    "            tokens = self.tokenizer.tokenize(row.text)\n",
    "            str_tokens = [str(token) for token in tokens]\n",
    "            selected_tokens = self.tokenizer.tokenize(row.selected_text)\n",
    "            start = str_tokens.index(str(selected_tokens[1]))\n",
    "            end = len(str_tokens) - str_tokens[::-1].index(str(selected_tokens[-2])) - 1\n",
    "            span = [start, end]\n",
    "            sentiment = self.tokenizer.tokenize(row.sentiment)[1:]\n",
    "            yield self.text_to_instance(tokens, sentiment, span)\n",
    "\n",
    "@Model.register(\"sentiment_extractor\")\n",
    "class TweetSentimentExtractor(Model):\n",
    "    def __init__(self,\n",
    "                 vocab: Vocabulary,\n",
    "                 embedder: TextFieldEmbedder,\n",
    "                 encoder: Seq2SeqEncoder):\n",
    "        super().__init__(vocab)\n",
    "        self.embedder = embedder\n",
    "        self.encoder = encoder\n",
    "        self.start = torch.nn.Linear(embedder.get_output_dim(), 1)\n",
    "        self.end = torch.nn.Linear(embedder.get_output_dim(), 1)\n",
    "\n",
    "    def forward(self,\n",
    "                text: Dict[str, torch.Tensor],\n",
    "                span: torch.Tensor = None) -> Dict[str, torch.Tensor]:\n",
    "        # Shape: (batch_size, num_tokens, embedding_dim)\n",
    "        embedded_text = self.embedder(text)\n",
    "        # Shape: (batch_size, num_tokens)\n",
    "        mask = util.get_text_field_mask(text)\n",
    "        # Shape: (batch_size, num_tokens, encoding_dim)\n",
    "        encoded_text = self.encoder(embedded_text, mask)\n",
    "        softmax_mask = torch.ones_like(mask, dtype=torch.float)\n",
    "        softmax_mask[:, 0] = 1e-12\n",
    "        softmax_mask[:, -3:] = 1e-12\n",
    "        # Shape: (batch_size, text_length)\n",
    "        start_logits = softmax_mask * self.start(encoded_text).squeeze()\n",
    "        # Shape: (batch_size, text_length)\n",
    "        end_logits = softmax_mask * self.end(encoded_text).squeeze()\n",
    "        # Shape: (batch_size, text_length)\n",
    "        start_probs = softmax_mask * torch.nn.functional.softmax(start_logits)\n",
    "        end_probs = softmax_mask * torch.nn.functional.softmax(end_logits)\n",
    "        # Shape: (1,)\n",
    "        output = {'start_probs': start_probs, 'end_probs': end_probs}\n",
    "        if span is not None:\n",
    "            output['start_loss'] = torch.nn.functional.cross_entropy(start_logits, span[:, 0])\n",
    "            output['end_loss'] = torch.nn.functional.cross_entropy(end_logits, span[:, 1])\n",
    "            output['loss'] = output['start_loss'] + output['end_loss']\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "bert_model = './models/bert/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "reader = SentimentDfReader(lazy=False, \n",
    "                          tokenizer=PretrainedTransformerTokenizer(bert_model),\n",
    "                          token_indexers={'bert_tokens': PretrainedTransformerIndexer(bert_model)},\n",
    "                          max_tokens=145)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fda84c1b3ea44a3bb25d51a12b0c0d7a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ef3f0a6774e543beb72b2ed74c1dc5fe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "train_instances = reader.read(os.path.join(data_dir, 'clean_train.csv'))\n",
    "valid_instances = reader.read(os.path.join(data_dir, 'clean_valid.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b9aaa57dbaa3439881fdf7152b630a16",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=27480.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "vocab = Vocabulary.from_instances(train_instances + valid_instances)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_instances.index_with(vocab)\n",
    "valid_instances.index_with(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding = PretrainedTransformerEmbedder(bert_model)\n",
    "embedder = BasicTextFieldEmbedder(token_embedders={'bert': embedding})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "s2sencoder = PassThroughEncoder(embedding.get_output_dim())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "768"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding.get_output_dim()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = TweetSentimentExtractor(vocab, embedder, s2sencoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_sampler = BucketBatchSampler(train_instances, batch_size=32, sorting_keys=['text'])\n",
    "train_loader = DataLoader(train_instances, batch_sampler=train_sampler)\n",
    "\n",
    "sampler = SequentialSampler(valid_instances)\n",
    "valid_sampler = BasicBatchSampler(sampler, batch_size=32, drop_last=False)\n",
    "valid_loader = DataLoader(valid_instances, batch_sampler=valid_sampler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d2fc7437e8b44e7da5f053505b180df7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=687.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Expected object of device type cuda but got device type cpu for argument #1 'self' in call to _th_index_select",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mRuntimeError\u001B[0m                              Traceback (most recent call last)",
      "\u001B[0;32m<ipython-input-68-f19b7863c0ed>\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[1;32m     11\u001B[0m                                  serialization_dir='./run/')\n\u001B[1;32m     12\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 13\u001B[0;31m \u001B[0mtrainer\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mtrain\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m",
      "\u001B[0;32m~/anaconda3/lib/python3.8/site-packages/allennlp/training/trainer.py\u001B[0m in \u001B[0;36mtrain\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m    800\u001B[0m         \u001B[0;32mfor\u001B[0m \u001B[0mepoch\u001B[0m \u001B[0;32min\u001B[0m \u001B[0mrange\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mepoch_counter\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_num_epochs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    801\u001B[0m             \u001B[0mepoch_start_time\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mtime\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mtime\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 802\u001B[0;31m             \u001B[0mtrain_metrics\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_train_epoch\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mepoch\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    803\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    804\u001B[0m             \u001B[0;31m# get peak of memory usage\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/anaconda3/lib/python3.8/site-packages/allennlp/training/trainer.py\u001B[0m in \u001B[0;36m_train_epoch\u001B[0;34m(self, epoch)\u001B[0m\n\u001B[1;32m    562\u001B[0m             \u001B[0mbatch_group_outputs\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0;34m[\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    563\u001B[0m             \u001B[0;32mfor\u001B[0m \u001B[0mbatch\u001B[0m \u001B[0;32min\u001B[0m \u001B[0mbatch_group\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 564\u001B[0;31m                 \u001B[0mbatch_outputs\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mbatch_outputs\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mbatch\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mfor_training\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;32mTrue\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    565\u001B[0m                 \u001B[0mbatch_group_outputs\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mappend\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mbatch_outputs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    566\u001B[0m                 \u001B[0mloss\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mbatch_outputs\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;34m\"loss\"\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/anaconda3/lib/python3.8/site-packages/allennlp/training/trainer.py\u001B[0m in \u001B[0;36mbatch_outputs\u001B[0;34m(self, batch, for_training)\u001B[0m\n\u001B[1;32m    460\u001B[0m         \"\"\"\n\u001B[1;32m    461\u001B[0m         \u001B[0mbatch\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mnn_util\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mmove_to_device\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mbatch\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mcuda_device\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 462\u001B[0;31m         \u001B[0moutput_dict\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_pytorch_model\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m**\u001B[0m\u001B[0mbatch\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    463\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    464\u001B[0m         \u001B[0;32mif\u001B[0m \u001B[0mfor_training\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/anaconda3/lib/python3.8/site-packages/torch/nn/modules/module.py\u001B[0m in \u001B[0;36m__call__\u001B[0;34m(self, *input, **kwargs)\u001B[0m\n\u001B[1;32m    548\u001B[0m             \u001B[0mresult\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_slow_forward\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m*\u001B[0m\u001B[0minput\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    549\u001B[0m         \u001B[0;32melse\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 550\u001B[0;31m             \u001B[0mresult\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mforward\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m*\u001B[0m\u001B[0minput\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    551\u001B[0m         \u001B[0;32mfor\u001B[0m \u001B[0mhook\u001B[0m \u001B[0;32min\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_forward_hooks\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mvalues\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    552\u001B[0m             \u001B[0mhook_result\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mhook\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0minput\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mresult\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m<ipython-input-64-37baaa4c20e7>\u001B[0m in \u001B[0;36mforward\u001B[0;34m(self, text, span)\u001B[0m\n\u001B[1;32m     51\u001B[0m                 span: torch.Tensor = None) -> Dict[str, torch.Tensor]:\n\u001B[1;32m     52\u001B[0m         \u001B[0;31m# Shape: (batch_size, num_tokens, embedding_dim)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 53\u001B[0;31m         \u001B[0membedded_text\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0membedder\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mtext\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     54\u001B[0m         \u001B[0;31m# Shape: (batch_size, num_tokens)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     55\u001B[0m         \u001B[0mmask\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mutil\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mget_text_field_mask\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mtext\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/anaconda3/lib/python3.8/site-packages/torch/nn/modules/module.py\u001B[0m in \u001B[0;36m__call__\u001B[0;34m(self, *input, **kwargs)\u001B[0m\n\u001B[1;32m    548\u001B[0m             \u001B[0mresult\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_slow_forward\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m*\u001B[0m\u001B[0minput\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    549\u001B[0m         \u001B[0;32melse\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 550\u001B[0;31m             \u001B[0mresult\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mforward\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m*\u001B[0m\u001B[0minput\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    551\u001B[0m         \u001B[0;32mfor\u001B[0m \u001B[0mhook\u001B[0m \u001B[0;32min\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_forward_hooks\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mvalues\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    552\u001B[0m             \u001B[0mhook_result\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mhook\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0minput\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mresult\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/anaconda3/lib/python3.8/site-packages/allennlp/modules/text_field_embedders/basic_text_field_embedder.py\u001B[0m in \u001B[0;36mforward\u001B[0;34m(self, text_field_input, num_wrapping_dims, **kwargs)\u001B[0m\n\u001B[1;32m     86\u001B[0m                 \u001B[0;31m# If there are multiple tensor arguments, we have to require matching names from the\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     87\u001B[0m                 \u001B[0;31m# TokenIndexer.  I don't think there's an easy way around that.\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 88\u001B[0;31m                 \u001B[0mtoken_vectors\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0membedder\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m**\u001B[0m\u001B[0mtensors\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mforward_params_values\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     89\u001B[0m             \u001B[0;32mif\u001B[0m \u001B[0mtoken_vectors\u001B[0m \u001B[0;32mis\u001B[0m \u001B[0;32mnot\u001B[0m \u001B[0;32mNone\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     90\u001B[0m                 \u001B[0;31m# To handle some very rare use cases, we allow the return value of the embedder to\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/anaconda3/lib/python3.8/site-packages/torch/nn/modules/module.py\u001B[0m in \u001B[0;36m__call__\u001B[0;34m(self, *input, **kwargs)\u001B[0m\n\u001B[1;32m    548\u001B[0m             \u001B[0mresult\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_slow_forward\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m*\u001B[0m\u001B[0minput\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    549\u001B[0m         \u001B[0;32melse\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 550\u001B[0;31m             \u001B[0mresult\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mforward\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m*\u001B[0m\u001B[0minput\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    551\u001B[0m         \u001B[0;32mfor\u001B[0m \u001B[0mhook\u001B[0m \u001B[0;32min\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_forward_hooks\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mvalues\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    552\u001B[0m             \u001B[0mhook_result\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mhook\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0minput\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mresult\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/anaconda3/lib/python3.8/site-packages/allennlp/modules/token_embedders/pretrained_transformer_embedder.py\u001B[0m in \u001B[0;36mforward\u001B[0;34m(self, token_ids, mask, type_ids, segment_concat_mask)\u001B[0m\n\u001B[1;32m    140\u001B[0m             \u001B[0;32mif\u001B[0m \u001B[0mtype_ids\u001B[0m \u001B[0;32mis\u001B[0m \u001B[0;32mnot\u001B[0m \u001B[0;32mNone\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    141\u001B[0m                 \u001B[0mparameters\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;34m\"token_type_ids\"\u001B[0m\u001B[0;34m]\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mtype_ids\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 142\u001B[0;31m             \u001B[0membeddings\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mtransformer_model\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m**\u001B[0m\u001B[0mparameters\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;36m0\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    143\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    144\u001B[0m             \u001B[0;32mif\u001B[0m \u001B[0mfold_long_sequences\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/anaconda3/lib/python3.8/site-packages/torch/nn/modules/module.py\u001B[0m in \u001B[0;36m__call__\u001B[0;34m(self, *input, **kwargs)\u001B[0m\n\u001B[1;32m    548\u001B[0m             \u001B[0mresult\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_slow_forward\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m*\u001B[0m\u001B[0minput\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    549\u001B[0m         \u001B[0;32melse\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 550\u001B[0;31m             \u001B[0mresult\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mforward\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m*\u001B[0m\u001B[0minput\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    551\u001B[0m         \u001B[0;32mfor\u001B[0m \u001B[0mhook\u001B[0m \u001B[0;32min\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_forward_hooks\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mvalues\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    552\u001B[0m             \u001B[0mhook_result\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mhook\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0minput\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mresult\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/anaconda3/lib/python3.8/site-packages/transformers/modeling_bert.py\u001B[0m in \u001B[0;36mforward\u001B[0;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask)\u001B[0m\n\u001B[1;32m    724\u001B[0m         \u001B[0mhead_mask\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mget_head_mask\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mhead_mask\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mconfig\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mnum_hidden_layers\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    725\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 726\u001B[0;31m         embedding_output = self.embeddings(\n\u001B[0m\u001B[1;32m    727\u001B[0m             \u001B[0minput_ids\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0minput_ids\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mposition_ids\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mposition_ids\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mtoken_type_ids\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mtoken_type_ids\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0minputs_embeds\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0minputs_embeds\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    728\u001B[0m         )\n",
      "\u001B[0;32m~/anaconda3/lib/python3.8/site-packages/torch/nn/modules/module.py\u001B[0m in \u001B[0;36m__call__\u001B[0;34m(self, *input, **kwargs)\u001B[0m\n\u001B[1;32m    548\u001B[0m             \u001B[0mresult\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_slow_forward\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m*\u001B[0m\u001B[0minput\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    549\u001B[0m         \u001B[0;32melse\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 550\u001B[0;31m             \u001B[0mresult\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mforward\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m*\u001B[0m\u001B[0minput\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    551\u001B[0m         \u001B[0;32mfor\u001B[0m \u001B[0mhook\u001B[0m \u001B[0;32min\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_forward_hooks\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mvalues\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    552\u001B[0m             \u001B[0mhook_result\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mhook\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0minput\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mresult\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/anaconda3/lib/python3.8/site-packages/transformers/modeling_bert.py\u001B[0m in \u001B[0;36mforward\u001B[0;34m(self, input_ids, token_type_ids, position_ids, inputs_embeds)\u001B[0m\n\u001B[1;32m    172\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    173\u001B[0m         \u001B[0;32mif\u001B[0m \u001B[0minputs_embeds\u001B[0m \u001B[0;32mis\u001B[0m \u001B[0;32mNone\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 174\u001B[0;31m             \u001B[0minputs_embeds\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mword_embeddings\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0minput_ids\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    175\u001B[0m         \u001B[0mposition_embeddings\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mposition_embeddings\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mposition_ids\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    176\u001B[0m         \u001B[0mtoken_type_embeddings\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mtoken_type_embeddings\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mtoken_type_ids\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/anaconda3/lib/python3.8/site-packages/torch/nn/modules/module.py\u001B[0m in \u001B[0;36m__call__\u001B[0;34m(self, *input, **kwargs)\u001B[0m\n\u001B[1;32m    548\u001B[0m             \u001B[0mresult\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_slow_forward\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m*\u001B[0m\u001B[0minput\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    549\u001B[0m         \u001B[0;32melse\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 550\u001B[0;31m             \u001B[0mresult\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mforward\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m*\u001B[0m\u001B[0minput\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    551\u001B[0m         \u001B[0;32mfor\u001B[0m \u001B[0mhook\u001B[0m \u001B[0;32min\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_forward_hooks\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mvalues\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    552\u001B[0m             \u001B[0mhook_result\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mhook\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0minput\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mresult\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/anaconda3/lib/python3.8/site-packages/torch/nn/modules/sparse.py\u001B[0m in \u001B[0;36mforward\u001B[0;34m(self, input)\u001B[0m\n\u001B[1;32m    110\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    111\u001B[0m     \u001B[0;32mdef\u001B[0m \u001B[0mforward\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0minput\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 112\u001B[0;31m         return F.embedding(\n\u001B[0m\u001B[1;32m    113\u001B[0m             \u001B[0minput\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mweight\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mpadding_idx\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mmax_norm\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    114\u001B[0m             self.norm_type, self.scale_grad_by_freq, self.sparse)\n",
      "\u001B[0;32m~/anaconda3/lib/python3.8/site-packages/torch/nn/functional.py\u001B[0m in \u001B[0;36membedding\u001B[0;34m(input, weight, padding_idx, max_norm, norm_type, scale_grad_by_freq, sparse)\u001B[0m\n\u001B[1;32m   1722\u001B[0m         \u001B[0;31m# remove once script supports set_grad_enabled\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1723\u001B[0m         \u001B[0m_no_grad_embedding_renorm_\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mweight\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0minput\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mmax_norm\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mnorm_type\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m-> 1724\u001B[0;31m     \u001B[0;32mreturn\u001B[0m \u001B[0mtorch\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0membedding\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mweight\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0minput\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mpadding_idx\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mscale_grad_by_freq\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0msparse\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m   1725\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1726\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;31mRuntimeError\u001B[0m: Expected object of device type cuda but got device type cpu for argument #1 'self' in call to _th_index_select"
     ]
    }
   ],
   "source": [
    "optimizer = optim.Adam(model.parameters(), lr=1e-4, weight_decay=1e-5)\n",
    "\n",
    "trainer = GradientDescentTrainer(model=model,\n",
    "                                 optimizer=optimizer,\n",
    "                                 data_loader=train_loader,\n",
    "                                 patience=5,\n",
    "                                 validation_metric=\"-loss\",\n",
    "                                 validation_data_loader=valid_loader,\n",
    "                                 num_epochs=20,\n",
    "                                 cuda_device=4,\n",
    "                                 serialization_dir='./run/')\n",
    "\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {\n",
    "    \"dataset_reader\" : {\n",
    "        \"type\": \"sentiment-df\",\n",
    "        \"tokenizer\": {\n",
    "            \"type\": \"pretrained_transformer\",\n",
    "            \"model_name\": bert_model,\n",
    "        },\n",
    "        \"token_indexers\": {\n",
    "            \"bert\": {\n",
    "                \"type\": \"pretrained_transformer\",\n",
    "                \"model_name\": bert_model,\n",
    "            }\n",
    "        },\n",
    "        \"max_tokens\": 145\n",
    "    },\n",
    "    \"train_data_path\": \"./data/clean_train.csv\",\n",
    "    \"validation_data_path\": \"./data/clean_valid.csv\",\n",
    "    \"model\": {\n",
    "        \"type\": \"sentiment_extractor\",\n",
    "        \"embedder\": {\n",
    "            \"token_embedders\": {\n",
    "                \"bert\": {\n",
    "                    \"type\": \"pretrained_transformer\",\n",
    "                    \"model_name\": bert_model\n",
    "                }\n",
    "            }\n",
    "        },\n",
    "        \"encoder\": {\n",
    "            \"type\": \"pass_through\",\n",
    "            \"input_dim\": 768\n",
    "        }\n",
    "    },\n",
    "    \"data_loader\": {\n",
    "        \"batch_size\": 256,\n",
    "        \"shuffle\": True\n",
    "    },\n",
    "    \"validation_data_loader\": {\n",
    "        \"batch_size\": 512,\n",
    "        \"shuffle\": False\n",
    "    },\n",
    "    \"trainer\": {\n",
    "        \"optimizer\": {\n",
    "            \"type\": \"huggingface_adamw\",\n",
    "            \"lr\": 1.0e-5\n",
    "        },\n",
    "        \"num_epochs\": 20,\n",
    "        \"patience\": 5,\n",
    "        \"serialization_dir\": './run/'\n",
    "    },\n",
    "    \"distributed\": {\n",
    "        \"cuda_devices\": [4,5,6,7]\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5fc9b9a9d06543798c77464682488af4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "171d7689b85c4c27bc57df501abe9903",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "26539e193e6c4ab5b2fb6e2b3bcdf045",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "Exception",
     "evalue": "\n\n-- Process 3 terminated with the following error:\nTraceback (most recent call last):\n  File \"/root/anaconda3/lib/python3.8/site-packages/torch/multiprocessing/spawn.py\", line 20, in _wrap\n    fn(i, *args)\n  File \"/root/anaconda3/lib/python3.8/site-packages/allennlp/commands/train.py\", line 417, in _train_worker\n    train_loop = TrainModel.from_params(\n  File \"/root/anaconda3/lib/python3.8/site-packages/allennlp/common/from_params.py\", line 576, in from_params\n    return retyped_subclass.from_params(\n  File \"/root/anaconda3/lib/python3.8/site-packages/allennlp/common/from_params.py\", line 609, in from_params\n    kwargs = create_kwargs(constructor_to_inspect, cls, params, **extras)\n  File \"/root/anaconda3/lib/python3.8/site-packages/allennlp/common/from_params.py\", line 180, in create_kwargs\n    constructed_arg = pop_and_construct_arg(\n  File \"/root/anaconda3/lib/python3.8/site-packages/allennlp/common/from_params.py\", line 287, in pop_and_construct_arg\n    return construct_arg(class_name, name, popped_params, annotation, default, **extras)\n  File \"/root/anaconda3/lib/python3.8/site-packages/allennlp/common/from_params.py\", line 321, in construct_arg\n    return annotation.from_params(params=popped_params, **subextras)\n  File \"/root/anaconda3/lib/python3.8/site-packages/allennlp/common/from_params.py\", line 557, in from_params\n    choice = params.pop_choice(\n  File \"/root/anaconda3/lib/python3.8/site-packages/allennlp/common/params.py\", line 351, in pop_choice\n    raise ConfigurationError(message)\nallennlp.common.checks.ConfigurationError: sentiment-df not in acceptable choices for dataset_reader.type: ['conll2003', 'interleaving', 'sequence_tagging', 'sharded', 'babi', 'text_classification_json']. You should either use the --include-package flag to make sure the correct module is loaded, or use a fully qualified class name in your config file like {\"model\": \"my_module.models.MyModel\"} to have it imported automatically.\n",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mException\u001B[0m                                 Traceback (most recent call last)",
      "\u001B[0;32m<ipython-input-53-7f4cffd5a015>\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[1;32m      6\u001B[0m \u001B[0;31m# Instead of this python code, you would typically just call\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      7\u001B[0m \u001B[0;31m# allennlp train [config_file] -s [serialization_dir]\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m----> 8\u001B[0;31m train_model_from_file(config_filename,\n\u001B[0m\u001B[1;32m      9\u001B[0m                       \u001B[0mserialization_dir\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     10\u001B[0m                       \u001B[0mfile_friendly_logging\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;32mTrue\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/anaconda3/lib/python3.8/site-packages/allennlp/commands/train.py\u001B[0m in \u001B[0;36mtrain_model_from_file\u001B[0;34m(parameter_filename, serialization_dir, overrides, file_friendly_logging, recover, force, node_rank, include_package, dry_run)\u001B[0m\n\u001B[1;32m    161\u001B[0m     \u001B[0;31m# Load the experiment config from a file and pass it to `train_model`.\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    162\u001B[0m     \u001B[0mparams\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mParams\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mfrom_file\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mparameter_filename\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0moverrides\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 163\u001B[0;31m     return train_model(\n\u001B[0m\u001B[1;32m    164\u001B[0m         \u001B[0mparams\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mparams\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    165\u001B[0m         \u001B[0mserialization_dir\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mserialization_dir\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/anaconda3/lib/python3.8/site-packages/allennlp/commands/train.py\u001B[0m in \u001B[0;36mtrain_model\u001B[0;34m(params, serialization_dir, file_friendly_logging, recover, force, node_rank, include_package, dry_run)\u001B[0m\n\u001B[1;32m    279\u001B[0m         }\n\u001B[1;32m    280\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 281\u001B[0;31m         mp.spawn(\n\u001B[0m\u001B[1;32m    282\u001B[0m             \u001B[0m_train_worker\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    283\u001B[0m             args=(\n",
      "\u001B[0;32m~/anaconda3/lib/python3.8/site-packages/torch/multiprocessing/spawn.py\u001B[0m in \u001B[0;36mspawn\u001B[0;34m(fn, args, nprocs, join, daemon, start_method)\u001B[0m\n\u001B[1;32m    198\u001B[0m                ' torch.multiprocessing.start_process(...)' % start_method)\n\u001B[1;32m    199\u001B[0m         \u001B[0mwarnings\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mwarn\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mmsg\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 200\u001B[0;31m     \u001B[0;32mreturn\u001B[0m \u001B[0mstart_processes\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mfn\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0margs\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mnprocs\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mjoin\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mdaemon\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mstart_method\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;34m'spawn'\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m",
      "\u001B[0;32m~/anaconda3/lib/python3.8/site-packages/torch/multiprocessing/spawn.py\u001B[0m in \u001B[0;36mstart_processes\u001B[0;34m(fn, args, nprocs, join, daemon, start_method)\u001B[0m\n\u001B[1;32m    156\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    157\u001B[0m     \u001B[0;31m# Loop on join until it returns True or raises an exception.\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 158\u001B[0;31m     \u001B[0;32mwhile\u001B[0m \u001B[0;32mnot\u001B[0m \u001B[0mcontext\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mjoin\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    159\u001B[0m         \u001B[0;32mpass\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    160\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/anaconda3/lib/python3.8/site-packages/torch/multiprocessing/spawn.py\u001B[0m in \u001B[0;36mjoin\u001B[0;34m(self, timeout)\u001B[0m\n\u001B[1;32m    117\u001B[0m         \u001B[0mmsg\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0;34m\"\\n\\n-- Process %d terminated with the following error:\\n\"\u001B[0m \u001B[0;34m%\u001B[0m \u001B[0merror_index\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    118\u001B[0m         \u001B[0mmsg\u001B[0m \u001B[0;34m+=\u001B[0m \u001B[0moriginal_trace\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 119\u001B[0;31m         \u001B[0;32mraise\u001B[0m \u001B[0mException\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mmsg\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    120\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    121\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;31mException\u001B[0m: \n\n-- Process 3 terminated with the following error:\nTraceback (most recent call last):\n  File \"/root/anaconda3/lib/python3.8/site-packages/torch/multiprocessing/spawn.py\", line 20, in _wrap\n    fn(i, *args)\n  File \"/root/anaconda3/lib/python3.8/site-packages/allennlp/commands/train.py\", line 417, in _train_worker\n    train_loop = TrainModel.from_params(\n  File \"/root/anaconda3/lib/python3.8/site-packages/allennlp/common/from_params.py\", line 576, in from_params\n    return retyped_subclass.from_params(\n  File \"/root/anaconda3/lib/python3.8/site-packages/allennlp/common/from_params.py\", line 609, in from_params\n    kwargs = create_kwargs(constructor_to_inspect, cls, params, **extras)\n  File \"/root/anaconda3/lib/python3.8/site-packages/allennlp/common/from_params.py\", line 180, in create_kwargs\n    constructed_arg = pop_and_construct_arg(\n  File \"/root/anaconda3/lib/python3.8/site-packages/allennlp/common/from_params.py\", line 287, in pop_and_construct_arg\n    return construct_arg(class_name, name, popped_params, annotation, default, **extras)\n  File \"/root/anaconda3/lib/python3.8/site-packages/allennlp/common/from_params.py\", line 321, in construct_arg\n    return annotation.from_params(params=popped_params, **subextras)\n  File \"/root/anaconda3/lib/python3.8/site-packages/allennlp/common/from_params.py\", line 557, in from_params\n    choice = params.pop_choice(\n  File \"/root/anaconda3/lib/python3.8/site-packages/allennlp/common/params.py\", line 351, in pop_choice\n    raise ConfigurationError(message)\nallennlp.common.checks.ConfigurationError: sentiment-df not in acceptable choices for dataset_reader.type: ['conll2003', 'interleaving', 'sequence_tagging', 'sharded', 'babi', 'text_classification_json']. You should either use the --include-package flag to make sure the correct module is loaded, or use a fully qualified class name in your config file like {\"model\": \"my_module.models.MyModel\"} to have it imported automatically.\n"
     ]
    }
   ],
   "source": [
    "serialization_dir = './run/'\n",
    "config_filename = serialization_dir + \"/training_config.json\"\n",
    "with open(config_filename, 'w') as config_file:\n",
    "    json.dump(config, config_file)\n",
    "from allennlp.commands.train import train_model_from_file\n",
    "# Instead of this python code, you would typically just call\n",
    "# allennlp train [config_file] -s [serialization_dir]\n",
    "train_model_from_file(config_filename,\n",
    "                      serialization_dir,\n",
    "                      file_friendly_logging=True,\n",
    "                      force=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}